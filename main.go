package main

import (
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"math"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"sync/atomic"
	"time"

	"bddisk_uploader/logger"
	"icode.baidu.com/baidu/xpan/go-sdk/xpan/upload"
)

const (
	ChunkSize = 4 * 1024 * 1024 // 4MBåˆ†ç‰‡å¤§å°
	ConfigFile = "config.json"
	MaxRetries = 3              // æœ€å¤§é‡è¯•æ¬¡æ•°
	BaseRetryDelay = 1 * time.Second // åŸºç¡€é‡è¯•å»¶è¿Ÿ
	DefaultCacheDir = ".chunks"        // é»˜è®¤ç¼“å­˜ç›®å½•
)

type Config struct {
	AccessToken  string      `json:"access_token"`
	RefreshToken string      `json:"refresh_token,omitempty"`
	ExpiresAt    *time.Time  `json:"expires_at,omitempty"`
	AppPath      string      `json:"app_path"` // åº”ç”¨è·¯å¾„å‰ç¼€ï¼Œå¦‚ "/apps/your_app_name/"
	OAuth        *OAuthConfig `json:"oauth,omitempty"`
}

// åŠ è½½é…ç½®æ–‡ä»¶
func loadConfig() (*Config, error) {
	configData, err := os.ReadFile(ConfigFile)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	var config Config
	if err := json.Unmarshal(configData, &config); err != nil {
		return nil, fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	if config.AccessToken == "" {
		return nil, fmt.Errorf("é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘access_token")
	}

	if config.AppPath == "" {
		config.AppPath = "/apps/baidu_netdisk_uploader/"
	}

	return &config, nil
}

// åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
func createDefaultConfig() error {
	config := Config{
		AccessToken: "your_access_token_here",
		AppPath:     "/apps/baidu_netdisk_uploader/",
		OAuth: &OAuthConfig{
			ClientID:     "your_app_key_here",
			ClientSecret: "your_secret_key_here",
			RedirectURI:  DefaultRedirectURI,
			Scope:        DefaultScope,
		},
	}

	configData, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		return err
	}

	return os.WriteFile(ConfigFile, configData, 0644)
}

// è®¡ç®—æ–‡ä»¶åˆ†ç‰‡çš„MD5å€¼
func calculateFileMD5Chunks(filePath string) ([]string, uint64, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, 0, err
	}
	defer file.Close()

	fileInfo, err := file.Stat()
	if err != nil {
		return nil, 0, err
	}

	fileSize := uint64(fileInfo.Size())
	var md5List []string
	buffer := make([]byte, ChunkSize)

	for {
		n, err := file.Read(buffer)
		if err != nil && err != io.EOF {
			return nil, 0, err
		}
		if n == 0 {
			break
		}

		hash := md5.Sum(buffer[:n])
		md5List = append(md5List, hex.EncodeToString(hash[:]))
	}

	return md5List, fileSize, nil
}

// è·å–ç¼“å­˜ç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
func getCacheDir(customCacheDir string) (string, error) {
	var cacheDir string
	
	if customCacheDir != "" {
		// ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ç¼“å­˜ç›®å½•
		cacheDir = customCacheDir
	} else {
		// ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ .chunks ç›®å½•ä½œä¸ºé»˜è®¤ç¼“å­˜ç›®å½•
		currentDir, err := os.Getwd()
		if err != nil {
			return "", fmt.Errorf("è·å–å½“å‰ç›®å½•å¤±è´¥: %v", err)
		}
		cacheDir = filepath.Join(currentDir, DefaultCacheDir)
	}
	
	// ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(cacheDir, 0755); err != nil {
		return "", fmt.Errorf("åˆ›å»ºç¼“å­˜ç›®å½•å¤±è´¥: %v", err)
	}
	
	return cacheDir, nil
}

// åˆ›å»ºæ–‡ä»¶åˆ†ç‰‡
func createFileChunks(filePath, cacheDir string) ([]string, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	var chunkFiles []string
	buffer := make([]byte, ChunkSize)
	chunkIndex := 0

	// è·å–åŸæ–‡ä»¶çš„åŸºæœ¬åç§°ï¼ˆä¸åŒ…å«è·¯å¾„ï¼‰
	baseFileName := filepath.Base(filePath)

	for {
		n, err := file.Read(buffer)
		if err != nil && err != io.EOF {
			return nil, err
		}
		if n == 0 {
			break
		}

		// åœ¨ç¼“å­˜ç›®å½•ä¸‹åˆ›å»ºåˆ†ç‰‡æ–‡ä»¶ï¼Œä½¿ç”¨åŸæ–‡ä»¶åå’Œè¿›ç¨‹IDç¡®ä¿å”¯ä¸€æ€§
		chunkFileName := filepath.Join(cacheDir, fmt.Sprintf("%s.%d.chunk.%d", baseFileName, os.Getpid(), chunkIndex))
		chunkFile, err := os.Create(chunkFileName)
		if err != nil {
			return nil, err
		}

		_, err = chunkFile.Write(buffer[:n])
		chunkFile.Close()
		if err != nil {
			return nil, err
		}

		chunkFiles = append(chunkFiles, chunkFileName)
		chunkIndex++
	}

	return chunkFiles, nil
}

// æ¸…ç†ä¸´æ—¶åˆ†ç‰‡æ–‡ä»¶
func cleanupChunks(chunkFiles []string) {
	if len(chunkFiles) == 0 {
		return
	}
	
	logger.Info("æ­£åœ¨æ¸…ç† %d ä¸ªåˆ†ç‰‡æ–‡ä»¶...", len(chunkFiles))
	cleanedCount := 0
	for _, chunkFile := range chunkFiles {
		if err := os.Remove(chunkFile); err != nil {
			logger.Debug("æ¸…ç†åˆ†ç‰‡æ–‡ä»¶å¤±è´¥: %s - %v", chunkFile, err)
			continue
		}
		cleanedCount++
	}
	logger.Info("å®Œæˆï¼Œå·²æ¸…ç† %d ä¸ªåˆ†ç‰‡æ–‡ä»¶", cleanedCount)
}

// åˆ¤æ–­æ˜¯å¦ä¸ºå¯é‡è¯•çš„é”™è¯¯
func isRetryableError(err error) bool {
	if err == nil {
		return false
	}
	errStr := strings.ToLower(err.Error())
	
	// å¯é‡è¯•çš„é”™è¯¯ç±»å‹
	retryableErrors := []string{
		"timeout",
		"connection reset",
		"connection refused", 
		"network unreachable",
		"temporary failure",
		"502 bad gateway",
		"503 service unavailable",
		"504 gateway timeout",
		"500 internal server error",
		"i/o timeout",
		"eof",
		"broken pipe",
	}
	
	for _, retryable := range retryableErrors {
		if strings.Contains(errStr, retryable) {
			return true
		}
	}
	return false
}

// å¸¦é‡è¯•çš„åˆ†ç‰‡ä¸Šä¼ å‡½æ•°
func uploadChunkWithRetry(accessToken string, uploadArg *upload.UploadArg, partSeq int) (upload.UploadReturn, error) {
	var lastErr error
	
	for attempt := 0; attempt <= MaxRetries; attempt++ {
		if attempt > 0 {
			// è®¡ç®—é€€é¿å»¶è¿Ÿï¼šæŒ‡æ•°é€€é¿ + éšæœºæŠ–åŠ¨
			delay := time.Duration(math.Pow(2, float64(attempt-1))) * BaseRetryDelay
			if delay > 30*time.Second {
				delay = 30 * time.Second // æœ€å¤§å»¶è¿Ÿ30ç§’
			}
			
			logger.Warn("åˆ†ç‰‡ %d ç¬¬ %d æ¬¡é‡è¯•ï¼Œç­‰å¾… %v...", partSeq+1, attempt, delay)
			time.Sleep(delay)
			logger.Debug("åˆ†ç‰‡ %d å¼€å§‹é‡è¯•", partSeq+1)
		}
		
		result, err := upload.Upload(accessToken, uploadArg)
		if err == nil {
			if attempt > 0 {
				logger.Info("åˆ†ç‰‡ %d é‡è¯•æˆåŠŸï¼", partSeq+1)
			}
			return result, nil
		}
		
		lastErr = err
		
		// å¦‚æœæ˜¯ä¸å¯é‡è¯•çš„é”™è¯¯ï¼Œç›´æ¥è¿”å›
		if !isRetryableError(err) {
			logger.Error("åˆ†ç‰‡ %d å‡ºç°ä¸å¯é‡è¯•é”™è¯¯: %v", partSeq+1, err)
			return upload.UploadReturn{}, err
		}
		
		logger.Warn("åˆ†ç‰‡ %d ä¸Šä¼ å¤±è´¥ (å°è¯• %d/%d): %v", partSeq+1, attempt+1, MaxRetries+1, err)
	}
	
	return upload.UploadReturn{}, fmt.Errorf("åˆ†ç‰‡ %d ä¸Šä¼ å¤±è´¥ï¼Œå·²å°è¯• %d æ¬¡: %v", partSeq, MaxRetries+1, lastErr)
}

// ä¸Šä¼ æ–‡ä»¶åˆ°ç™¾åº¦ç½‘ç›˜
func uploadFileWithCacheDir(config *Config, localFilePath, remoteFileName, cacheDir string) error {
	// è®¡ç®—æ–‡ä»¶MD5åˆ†ç‰‡
	logger.Progress("æ­£åœ¨è®¡ç®—æ–‡ä»¶MD5åˆ†ç‰‡...")
	md5List, fileSize, err := calculateFileMD5Chunks(localFilePath)
	if err != nil {
		return fmt.Errorf("è®¡ç®—æ–‡ä»¶MD5å¤±è´¥: %v", err)
	}
	logger.Info("å®Œæˆï¼Œæ–‡ä»¶å¤§å°: %d å­—èŠ‚ï¼Œåˆ†ç‰‡æ•°: %d", fileSize, len(md5List))

	// æ„å»ºè¿œç¨‹è·¯å¾„
	remotePath := filepath.Join(config.AppPath, remoteFileName)
	remotePath = strings.ReplaceAll(remotePath, "\\", "/") // ç¡®ä¿ä½¿ç”¨Unixé£æ ¼è·¯å¾„

	// 1. Precreate - é¢„åˆ›å»ºæ–‡ä»¶
	logger.Progress("æ­£åœ¨é¢„åˆ›å»ºæ–‡ä»¶...")
	precreateArg := upload.NewPrecreateArg(remotePath, fileSize, md5List)
	precreateResult, err := upload.Precreate(config.AccessToken, precreateArg)
	if err != nil {
		return fmt.Errorf("é¢„åˆ›å»ºæ–‡ä»¶å¤±è´¥: %v", err)
	}
	logger.Debug("å®Œæˆï¼Œä¸Šä¼ ID: %s", precreateResult.UploadId)

	if precreateResult.ReturnType == 2 {
		logger.Info("æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸Šä¼ ")
		return nil
	}

	// åˆ›å»ºä¸´æ—¶åˆ†ç‰‡æ–‡ä»¶
	logger.Progress("æ­£åœ¨åˆ›å»ºæ–‡ä»¶åˆ†ç‰‡...")
	chunkFiles, err := createFileChunks(localFilePath, cacheDir)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºæ–‡ä»¶åˆ†ç‰‡å¤±è´¥: %v", err)
	}
	defer cleanupChunks(chunkFiles)
	logger.Debug("å®Œæˆï¼Œå…±åˆ›å»º %d ä¸ªåˆ†ç‰‡", len(chunkFiles))

	// 2. Upload - ä¸Šä¼ éœ€è¦çš„åˆ†ç‰‡ï¼ˆå¸¦é‡è¯•ï¼‰
	for _, partSeq := range precreateResult.BlockList {
		if partSeq >= len(chunkFiles) {
			return fmt.Errorf("åˆ†ç‰‡åºå· %d è¶…å‡ºèŒƒå›´", partSeq)
		}

		logger.Progress("æ­£åœ¨ä¸Šä¼ åˆ†ç‰‡ %d/%d...", partSeq+1, len(md5List))
		uploadArg := upload.NewUploadArg(
			precreateResult.UploadId,
			remotePath,
			chunkFiles[partSeq],
			partSeq,
		)

		uploadResult, err := uploadChunkWithRetry(config.AccessToken, uploadArg, partSeq)
		if err != nil {
			return fmt.Errorf("ä¸Šä¼ åˆ†ç‰‡ %d å¤±è´¥: %v", partSeq, err)
		}
		logger.Debug("åˆ†ç‰‡ %d ä¸Šä¼ å®Œæˆï¼ŒMD5: %s", partSeq+1, uploadResult.Md5)
	}

	// 3. Create - åˆ›å»ºæ–‡ä»¶
	logger.Progress("æ­£åœ¨åˆå¹¶æ–‡ä»¶...")
	createArg := upload.NewCreateArg(precreateResult.UploadId, remotePath, fileSize, md5List)
	createResult, err := upload.Create(config.AccessToken, createArg)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºæ–‡ä»¶å¤±è´¥: %v", err)
	}

	if createResult.Errno != 0 {
		return fmt.Errorf("åˆ›å»ºæ–‡ä»¶å¤±è´¥ï¼Œé”™è¯¯ç : %d", createResult.Errno)
	}

	logger.Info("å®Œæˆï¼æ–‡ä»¶å·²æˆåŠŸä¸Šä¼ åˆ°: %s", createResult.Path)
	return nil
}

func main() {
	var localFilePath, localFolderPath, remoteFileName, authCode, refreshToken, excludePatterns, cacheDir string
	var logFile, logLevel string
	var initConfig, auth, refresh, keepStructure, quietMode bool
	var authPort, maxConcurrent int

	flag.StringVar(&localFilePath, "file", "", "è¦ä¸Šä¼ çš„æœ¬åœ°æ–‡ä»¶è·¯å¾„")
	flag.StringVar(&localFolderPath, "folder", "", "è¦ä¸Šä¼ çš„æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„")
	flag.StringVar(&remoteFileName, "name", "", "ä¸Šä¼ åˆ°ç½‘ç›˜çš„æ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨æœ¬åœ°æ–‡ä»¶åï¼‰")
	flag.StringVar(&excludePatterns, "exclude", "", "è¦æ’é™¤çš„æ–‡ä»¶æ¨¡å¼ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¦‚ï¼š*.tmp,*.log,.DS_Storeï¼‰")
	flag.StringVar(&cacheDir, "cache-dir", "", "æŒ‡å®šåˆ†ç‰‡ç¼“å­˜ç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„.chunksï¼‰")
	flag.StringVar(&logFile, "log-file", "", "æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤åªè¾“å‡ºåˆ°æ§åˆ¶å°ï¼‰")
	flag.StringVar(&logLevel, "log-level", "info", "æ—¥å¿—çº§åˆ« (debug,info,warn,error,fatal)")
	flag.StringVar(&authCode, "code", "", "æˆæƒç ï¼ˆç”¨äºè·å–access_tokenï¼‰")
	flag.StringVar(&refreshToken, "refresh", "", "åˆ·æ–°token")
	flag.BoolVar(&initConfig, "init", false, "åˆå§‹åŒ–é…ç½®æ–‡ä»¶")
	flag.BoolVar(&auth, "auth", false, "å¯åŠ¨æˆæƒæµç¨‹")
	flag.BoolVar(&refresh, "refresh-token", false, "ä½¿ç”¨refresh_tokenåˆ·æ–°access_token")
	flag.BoolVar(&keepStructure, "keep-structure", true, "ä¿æŒæ–‡ä»¶å¤¹ç»“æ„ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")
	flag.BoolVar(&quietMode, "quiet", false, "é™é»˜æ¨¡å¼ï¼ˆå‡å°‘è¾“å‡ºä¿¡æ¯ï¼‰")
	flag.IntVar(&authPort, "port", 8080, "æˆæƒå›è°ƒæœåŠ¡å™¨ç«¯å£")
	flag.IntVar(&maxConcurrent, "concurrent", 3, "æœ€å¤§å¹¶å‘ä¸Šä¼ æ•°ï¼ˆé»˜è®¤3ï¼‰")
	flag.Parse()

	// è§£ææ—¥å¿—çº§åˆ«
	var level logger.LogLevel
	switch strings.ToLower(logLevel) {
	case "debug":
		level = logger.DEBUG
	case "info":
		level = logger.INFO
	case "warn", "warning":
		level = logger.WARN
	case "error":
		level = logger.ERROR
	case "fatal":
		level = logger.FATAL
	default:
		fmt.Printf("æ— æ•ˆçš„æ—¥å¿—çº§åˆ«: %sï¼Œä½¿ç”¨é»˜è®¤çº§åˆ« info\n", logLevel)
		level = logger.INFO
	}

	// åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
	showProgress := !quietMode
	if err := logger.Init(level, logFile, showProgress); err != nil {
		fmt.Printf("åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿå¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// åˆå§‹åŒ–é…ç½®æ–‡ä»¶
	if initConfig {
		if err := createDefaultConfig(); err != nil {
			logger.Error("åˆ›å»ºé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
			os.Exit(1)
		}
		logger.Info("å·²åˆ›å»ºé…ç½®æ–‡ä»¶ %s", ConfigFile)
		logger.Info("è¯·ç¼–è¾‘é…ç½®æ–‡ä»¶ä¸­çš„ä»¥ä¸‹ä¿¡æ¯:")
		logger.Info("  - client_id: æ‚¨çš„App Key")
		logger.Info("  - client_secret: æ‚¨çš„Secret Key")
		logger.Info("  - app_path: æ–‡ä»¶ä¸Šä¼ è·¯å¾„å‰ç¼€")
		logger.Info("ç„¶åè¿è¡Œ: ./bddisk_uploader -auth è¿›è¡Œæˆæƒ")
		return
	}

	// å¤„ç†æˆæƒæµç¨‹
	if auth {
		config, err := loadConfigForAuth()
		if err != nil {
			logger.Error("åŠ è½½é…ç½®å¤±è´¥: %v", err)
			os.Exit(1)
		}

		tokenResp, err := startAuthServer(config.OAuth, authPort)
		if err != nil {
			logger.Error("æˆæƒå¤±è´¥: %v", err)
			os.Exit(1)
		}

		// ä¿å­˜tokenåˆ°é…ç½®æ–‡ä»¶
		if err := saveTokenToConfig(tokenResp); err != nil {
			logger.Error("ä¿å­˜tokenå¤±è´¥: %v", err)
			os.Exit(1)
		}

		logger.Info("æˆæƒæˆåŠŸï¼access_tokenå·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶")
		return
	}

	// æ‰‹åŠ¨ä½¿ç”¨æˆæƒç è·å–token
	if authCode != "" {
		config, err := loadConfigForAuth()
		if err != nil {
			logger.Error("åŠ è½½é…ç½®å¤±è´¥: %v", err)
			os.Exit(1)
		}

		tokenResp, err := getAccessToken(config.OAuth, authCode)
		if err != nil {
			logger.Error("è·å–tokenå¤±è´¥: %v", err)
			os.Exit(1)
		}

		if err := saveTokenToConfig(tokenResp); err != nil {
			logger.Error("ä¿å­˜tokenå¤±è´¥: %v", err)
			os.Exit(1)
		}

		logger.Info("access_tokenè·å–æˆåŠŸå¹¶å·²ä¿å­˜ï¼")
		return
	}

	// åˆ·æ–°access_token
	if refresh {
		config, err := loadConfigForAuth()
		if err != nil {
			logger.Error("åŠ è½½é…ç½®å¤±è´¥: %v", err)
			os.Exit(1)
		}

		if config.RefreshToken == "" {
			logger.Error("é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰refresh_tokenï¼Œè¯·é‡æ–°æˆæƒ")
			os.Exit(1)
		}

		tokenResp, err := refreshAccessToken(config.OAuth, config.RefreshToken)
		if err != nil {
			logger.Error("åˆ·æ–°tokenå¤±è´¥: %v", err)
			os.Exit(1)
		}

		if err := saveTokenToConfig(tokenResp); err != nil {
			logger.Error("ä¿å­˜tokenå¤±è´¥: %v", err)
			os.Exit(1)
		}

		logger.Info("access_tokenåˆ·æ–°æˆåŠŸï¼")
		return
	}

	// æ£€æŸ¥å‚æ•°
	if localFilePath == "" && localFolderPath == "" {
		fmt.Println("ä½¿ç”¨æ–¹æ³•:")
		fmt.Println("  åˆå§‹åŒ–é…ç½®: ./bddisk_uploader -init")
		fmt.Println("  æˆæƒç™»å½•: ./bddisk_uploader -auth")
		fmt.Println("  æ‰‹åŠ¨æˆæƒ: ./bddisk_uploader -code <æˆæƒç >")
		fmt.Println("  åˆ·æ–°token: ./bddisk_uploader -refresh-token")
		fmt.Println("  ä¸Šä¼ æ–‡ä»¶: ./bddisk_uploader -file <æœ¬åœ°æ–‡ä»¶è·¯å¾„> [-name <è¿œç¨‹æ–‡ä»¶å>]")
		fmt.Println("  ä¸Šä¼ æ–‡ä»¶å¤¹: ./bddisk_uploader -folder <æœ¬åœ°æ–‡ä»¶å¤¹è·¯å¾„> [é€‰é¡¹]")
		fmt.Println("")
		fmt.Println("æ–‡ä»¶å¤¹ä¸Šä¼ é€‰é¡¹:")
		fmt.Println("  -exclude <æ¨¡å¼>        æ’é™¤æ–‡ä»¶æ¨¡å¼ï¼Œé€—å·åˆ†éš”")
		fmt.Println("  -keep-structure       ä¿æŒæ–‡ä»¶å¤¹ç»“æ„ï¼ˆé»˜è®¤å¯ç”¨ï¼‰")
		fmt.Println("  -concurrent <æ•°é‡>     æœ€å¤§å¹¶å‘ä¸Šä¼ æ•°ï¼ˆé»˜è®¤3ï¼‰")
		fmt.Println("  -cache-dir <è·¯å¾„>      æŒ‡å®šåˆ†ç‰‡ç¼“å­˜ç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„.chunksï¼‰")
		fmt.Println("")
		fmt.Println("æ—¥å¿—é€‰é¡¹:")
		fmt.Println("  -log-file <è·¯å¾„>       æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤åªè¾“å‡ºåˆ°æ§åˆ¶å°ï¼‰")
		fmt.Println("  -log-level <çº§åˆ«>      æ—¥å¿—çº§åˆ«ï¼ˆdebug,info,warn,error,fatalï¼Œé»˜è®¤infoï¼‰")
		fmt.Println("  -quiet                é™é»˜æ¨¡å¼ï¼ˆå‡å°‘è¾“å‡ºä¿¡æ¯ï¼‰")
		os.Exit(1)
	}

	// æ£€æŸ¥äº’æ–¥å‚æ•°
	if localFilePath != "" && localFolderPath != "" {
		logger.Error("é”™è¯¯: -file å’Œ -folder å‚æ•°ä¸èƒ½åŒæ—¶ä½¿ç”¨")
		os.Exit(1)
	}

	// æ£€æŸ¥æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
	var targetPath string
	var isFolder bool
	
	if localFolderPath != "" {
		targetPath = localFolderPath
		isFolder = true
		if _, err := os.Stat(targetPath); os.IsNotExist(err) {
			logger.Error("æ–‡ä»¶å¤¹ä¸å­˜åœ¨: %s", targetPath)
			os.Exit(1)
		}
		// æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
		if fileInfo, err := os.Stat(targetPath); err == nil && !fileInfo.IsDir() {
			logger.Error("é”™è¯¯: %s ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹", targetPath)
			os.Exit(1)
		}
	} else {
		targetPath = localFilePath
		isFolder = false
		if _, err := os.Stat(targetPath); os.IsNotExist(err) {
			logger.Error("æ–‡ä»¶ä¸å­˜åœ¨: %s", targetPath)
			os.Exit(1)
		}
		// å¦‚æœæ²¡æœ‰æŒ‡å®šè¿œç¨‹æ–‡ä»¶åï¼Œä½¿ç”¨æœ¬åœ°æ–‡ä»¶å
		if remoteFileName == "" {
			remoteFileName = filepath.Base(targetPath)
		}
	}

	// åŠ è½½é…ç½®
	config, err := loadConfig()
	if err != nil {
		logger.Error("é…ç½®é”™è¯¯: %v", err)
		logger.Error("è¯·å…ˆè¿è¡Œ: ./bddisk_uploader -init æ¥åˆ›å»ºé…ç½®æ–‡ä»¶")
		os.Exit(1)
	}

	// æ£€æŸ¥tokenæ˜¯å¦è¿‡æœŸ
	if config.ExpiresAt != nil && time.Now().After(*config.ExpiresAt) {
		logger.Warn("access_tokenå·²è¿‡æœŸï¼Œå°è¯•è‡ªåŠ¨åˆ·æ–°...")
		if config.RefreshToken != "" && config.OAuth != nil {
			tokenResp, err := refreshAccessToken(config.OAuth, config.RefreshToken)
			if err != nil {
				logger.Error("è‡ªåŠ¨åˆ·æ–°tokenå¤±è´¥: %v", err)
				logger.Error("è¯·é‡æ–°æˆæƒ: ./bddisk_uploader -auth")
				os.Exit(1)
			}
			if err := saveTokenToConfig(tokenResp); err != nil {
				logger.Error("ä¿å­˜æ–°tokenå¤±è´¥: %v", err)
				os.Exit(1)
			}
			config.AccessToken = tokenResp.AccessToken
			logger.Info("access_tokenå·²è‡ªåŠ¨åˆ·æ–°")
		} else {
			logger.Error("æ— æ³•è‡ªåŠ¨åˆ·æ–°tokenï¼Œè¯·é‡æ–°æˆæƒ: ./bddisk_uploader -auth")
			os.Exit(1)
		}
	}

	// è·å–ç¼“å­˜ç›®å½•
	actualCacheDir, err := getCacheDir(cacheDir)
	if err != nil {
		logger.Error("è·å–ç¼“å­˜ç›®å½•å¤±è´¥: %v", err)
		os.Exit(1)
	}
	logger.Info("ä½¿ç”¨ç¼“å­˜ç›®å½•: %s", actualCacheDir)

	// ä¸Šä¼ æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹
	if isFolder {
		// ä¸Šä¼ æ–‡ä»¶å¤¹
		excludeList := parseExcludePatterns(excludePatterns)
		logger.Info("å¼€å§‹ä¸Šä¼ æ–‡ä»¶å¤¹: %s", targetPath)
		if err := uploadFolderWithCacheDir(config, targetPath, excludeList, keepStructure, maxConcurrent, actualCacheDir); err != nil {
			logger.Error("ä¸Šä¼ å¤±è´¥: %v", err)
			os.Exit(1)
		}
		logger.Info("æ–‡ä»¶å¤¹ä¸Šä¼ å®Œæˆï¼")
	} else {
		// ä¸Šä¼ å•ä¸ªæ–‡ä»¶
		logger.Info("å¼€å§‹ä¸Šä¼ æ–‡ä»¶: %s -> %s", targetPath, remoteFileName)
		if err := uploadFileWithCacheDir(config, targetPath, remoteFileName, actualCacheDir); err != nil {
			logger.Error("ä¸Šä¼ å¤±è´¥: %v", err)
			os.Exit(1)
		}
		logger.Info("ä¸Šä¼ æˆåŠŸï¼")
	}
}

// åŠ è½½é…ç½®ç”¨äºæˆæƒï¼ˆä¸è¦æ±‚access_tokenå­˜åœ¨ï¼‰
func loadConfigForAuth() (*Config, error) {
	configData, err := os.ReadFile(ConfigFile)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	var config Config
	if err := json.Unmarshal(configData, &config); err != nil {
		return nil, fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	if config.OAuth == nil {
		return nil, fmt.Errorf("é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘OAuthä¿¡æ¯")
	}

	if config.OAuth.ClientID == "" || config.OAuth.ClientID == "your_app_key_here" {
		return nil, fmt.Errorf("è¯·å…ˆåœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„client_id (App Key)")
	}

	if config.OAuth.ClientSecret == "" || config.OAuth.ClientSecret == "your_secret_key_here" {
		return nil, fmt.Errorf("è¯·å…ˆåœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æ­£ç¡®çš„client_secret (Secret Key)")
	}

	if config.AppPath == "" {
		config.AppPath = "/apps/baidu_netdisk_uploader/"
	}

	return &config, nil
}

// ä¿å­˜tokenåˆ°é…ç½®æ–‡ä»¶
func saveTokenToConfig(tokenResp *TokenResponse) error {
	// è¯»å–ç°æœ‰é…ç½®
	config, err := loadConfigForAuth()
	if err != nil {
		return err
	}

	// æ›´æ–°tokenä¿¡æ¯
	config.AccessToken = tokenResp.AccessToken
	if tokenResp.RefreshToken != "" {
		config.RefreshToken = tokenResp.RefreshToken
	}
	
	// è®¡ç®—è¿‡æœŸæ—¶é—´
	if tokenResp.ExpiresIn > 0 {
		expiresAt := time.Now().Add(time.Duration(tokenResp.ExpiresIn) * time.Second)
		config.ExpiresAt = &expiresAt
	}

	// ä¿å­˜åˆ°æ–‡ä»¶
	configData, err := json.MarshalIndent(config, "", "  ")
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–é…ç½®å¤±è´¥: %v", err)
	}

	return os.WriteFile(ConfigFile, configData, 0644)
}

// æ–‡ä»¶ä¿¡æ¯ç»“æ„
type FileInfo struct {
	LocalPath  string
	RemotePath string
	Size       int64
	ModTime    time.Time
}

// ä¸Šä¼ ç»“æœç»Ÿè®¡
type UploadStats struct {
	TotalFiles    int64
	UploadedFiles int64
	FailedFiles   int64
	TotalSize     int64
	UploadedSize  int64
	StartTime     time.Time
}

// è§£ææ’é™¤æ¨¡å¼
func parseExcludePatterns(patterns string) []string {
	if patterns == "" {
		return []string{}
	}
	
	parts := strings.Split(patterns, ",")
	var result []string
	for _, part := range parts {
		part = strings.TrimSpace(part)
		if part != "" {
			result = append(result, part)
		}
	}
	return result
}

// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ’é™¤
func shouldExcludeFile(filePath string, excludePatterns []string) bool {
	fileName := filepath.Base(filePath)
	
	// é»˜è®¤æ’é™¤çš„æ–‡ä»¶
	defaultExcludes := []string{
		".DS_Store",
		"Thumbs.db",
		".git",
		".svn",
		".hg",
		"node_modules",
		"*.tmp",
		"*.temp",
		"*~",
	}
	
	allPatterns := append(excludePatterns, defaultExcludes...)
	
	for _, pattern := range allPatterns {
		if matched, _ := filepath.Match(pattern, fileName); matched {
			return true
		}
		// ä¹Ÿæ£€æŸ¥å®Œæ•´è·¯å¾„
		if matched, _ := filepath.Match(pattern, filePath); matched {
			return true
		}
	}
	return false
}

// æ”¶é›†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
func collectFiles(folderPath string, excludePatterns []string, keepStructure bool) ([]FileInfo, error) {
	var files []FileInfo
	
	// è·å–æ–‡ä»¶å¤¹åç§°ï¼Œç”¨äºä¿æŒå®Œæ•´çš„ç›®å½•ç»“æ„
	folderName := filepath.Base(folderPath)
	
	err := filepath.Walk(folderPath, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			logger.Warn("è­¦å‘Š: è®¿é—®æ–‡ä»¶å¤±è´¥ %s: %v", path, err)
			return nil // ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶
		}
		
		// è·³è¿‡ç›®å½•
		if info.IsDir() {
			return nil
		}
		
		// æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤
		if shouldExcludeFile(path, excludePatterns) {
			logger.Debug("è·³è¿‡æ–‡ä»¶: %s", path)
			return nil
		}
		
		// è®¡ç®—è¿œç¨‹è·¯å¾„
		var remotePath string
		if keepStructure {
			// ä¿æŒç›®å½•ç»“æ„ï¼ŒåŒ…å«æœ€å¤–å±‚æ–‡ä»¶å¤¹å
			relPath, err := filepath.Rel(folderPath, path)
			if err != nil {
				return fmt.Errorf("è®¡ç®—ç›¸å¯¹è·¯å¾„å¤±è´¥: %v", err)
			}
			// å°†æ–‡ä»¶å¤¹åç§°ä½œä¸ºæ ¹ç›®å½•
			remotePath = filepath.Join(folderName, relPath)
			remotePath = strings.ReplaceAll(remotePath, "\\", "/")
		} else {
			// å¹³é“ºæ‰€æœ‰æ–‡ä»¶åˆ°æ–‡ä»¶å¤¹æ ¹ç›®å½•
			remotePath = filepath.Join(folderName, info.Name())
			remotePath = strings.ReplaceAll(remotePath, "\\", "/")
		}
		
		files = append(files, FileInfo{
			LocalPath:  path,
			RemotePath: remotePath,
			Size:       info.Size(),
			ModTime:    info.ModTime(),
		})
		
		return nil
	})
	
	return files, err
}

// ä¸Šä¼ å•ä¸ªæ–‡ä»¶ï¼ˆç”¨äºå¹¶å‘ä¸Šä¼ ï¼‰- æ”¯æŒç¼“å­˜ç›®å½•
func uploadSingleFileWithCacheDir(config *Config, fileInfo FileInfo, stats *UploadStats, wg *sync.WaitGroup, semaphore chan struct{}, cacheDir string) {
	defer wg.Done()
	defer func() { <-semaphore }() // é‡Šæ”¾ä¿¡å·é‡
	
	fmt.Printf("[%d/%d] ä¸Šä¼ : %s\n", 
		atomic.LoadInt64(&stats.UploadedFiles)+atomic.LoadInt64(&stats.FailedFiles)+1, 
		stats.TotalFiles, 
		fileInfo.RemotePath)
	
	err := uploadFileWithCacheDir(config, fileInfo.LocalPath, fileInfo.RemotePath, cacheDir)
	if err != nil {
		atomic.AddInt64(&stats.FailedFiles, 1)
		fmt.Printf("âŒ ä¸Šä¼ å¤±è´¥: %s - %v\n", fileInfo.RemotePath, err)
	} else {
		atomic.AddInt64(&stats.UploadedFiles, 1)
		atomic.AddInt64(&stats.UploadedSize, fileInfo.Size)
		fmt.Printf("âœ… ä¸Šä¼ æˆåŠŸ: %s\n", fileInfo.RemotePath)
	}
}

// æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
func formatFileSize(size int64) string {
	const unit = 1024
	if size < unit {
		return fmt.Sprintf("%d B", size)
	}
	div, exp := int64(unit), 0
	for n := size / unit; n >= unit; n /= unit {
		div *= unit
		exp++
	}
	return fmt.Sprintf("%.1f %cB", float64(size)/float64(div), "KMGTPE"[exp])
}

// æ ¼å¼åŒ–æŒç»­æ—¶é—´
func formatDuration(d time.Duration) string {
	if d < time.Minute {
		return fmt.Sprintf("%.1fs", d.Seconds())
	} else if d < time.Hour {
		return fmt.Sprintf("%.1fm", d.Minutes())
	} else {
		return fmt.Sprintf("%.1fh", d.Hours())
	}
}

// ä¸Šä¼ æ–‡ä»¶å¤¹ - æ”¯æŒç¼“å­˜ç›®å½•
func uploadFolderWithCacheDir(config *Config, folderPath string, excludePatterns []string, keepStructure bool, maxConcurrent int, cacheDir string) error {
	// æ”¶é›†æ‰€æœ‰éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶
	logger.Info("æ­£åœ¨æ‰«ææ–‡ä»¶...")
	files, err := collectFiles(folderPath, excludePatterns, keepStructure)
	if err != nil {
		return fmt.Errorf("æ”¶é›†æ–‡ä»¶å¤±è´¥: %v", err)
	}
	
	if len(files) == 0 {
		fmt.Println("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ä¸Šä¼ çš„æ–‡ä»¶")
		return nil
	}
	
	// è®¡ç®—æ€»å¤§å°
	var totalSize int64
	for _, file := range files {
		totalSize += file.Size
	}
	
	// åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
	stats := &UploadStats{
		TotalFiles: int64(len(files)),
		TotalSize:  totalSize,
		StartTime:  time.Now(),
	}
	
	fmt.Printf("å‘ç° %d ä¸ªæ–‡ä»¶ï¼Œæ€»å¤§å°: %s\n", len(files), formatFileSize(totalSize))
	fmt.Printf("å¼€å§‹å¹¶å‘ä¸Šä¼  (æœ€å¤§å¹¶å‘æ•°: %d)...\n\n", maxConcurrent)
	
	// åˆ›å»ºä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
	semaphore := make(chan struct{}, maxConcurrent)
	var wg sync.WaitGroup
	
	// å¯åŠ¨è¿›åº¦ç›‘æ§
	done := make(chan bool)
	go func() {
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()
		
		for {
			select {
			case <-ticker.C:
				uploaded := atomic.LoadInt64(&stats.UploadedFiles)
				failed := atomic.LoadInt64(&stats.FailedFiles)
				uploadedSize := atomic.LoadInt64(&stats.UploadedSize)
				
				progress := float64(uploaded+failed) / float64(stats.TotalFiles) * 100
				elapsed := time.Since(stats.StartTime)
				
				fmt.Printf("\nğŸ“Š è¿›åº¦æŠ¥å‘Š: %.1f%% (%d/%d) | æˆåŠŸ: %d | å¤±è´¥: %d | å·²ä¼ è¾“: %s/%s | è€—æ—¶: %s\n\n",
					progress, uploaded+failed, stats.TotalFiles, uploaded, failed,
					formatFileSize(uploadedSize), formatFileSize(totalSize), formatDuration(elapsed))
			case <-done:
				return
			}
		}
	}()
	
	// å¹¶å‘ä¸Šä¼ æ–‡ä»¶
	for _, file := range files {
		semaphore <- struct{}{} // è·å–ä¿¡å·é‡
		wg.Add(1)
		go uploadSingleFileWithCacheDir(config, file, stats, &wg, semaphore, cacheDir)
	}
	
	// ç­‰å¾…æ‰€æœ‰ä¸Šä¼ å®Œæˆ
	wg.Wait()
	done <- true
	
	// æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
	elapsed := time.Since(stats.StartTime)
	uploaded := atomic.LoadInt64(&stats.UploadedFiles)
	failed := atomic.LoadInt64(&stats.FailedFiles)
	uploadedSize := atomic.LoadInt64(&stats.UploadedSize)
	
	fmt.Printf("\nğŸ‰ ä¸Šä¼ å®Œæˆ!\n")
	fmt.Printf("æ€»æ–‡ä»¶æ•°: %d\n", stats.TotalFiles)
	fmt.Printf("æˆåŠŸä¸Šä¼ : %d\n", uploaded)
	fmt.Printf("å¤±è´¥æ–‡ä»¶: %d\n", failed)
	fmt.Printf("ä¼ è¾“å¤§å°: %s / %s\n", formatFileSize(uploadedSize), formatFileSize(totalSize))
	fmt.Printf("æ€»è€—æ—¶: %s\n", formatDuration(elapsed))
	
	if uploaded > 0 {
		avgSpeed := float64(uploadedSize) / elapsed.Seconds()
		fmt.Printf("å¹³å‡é€Ÿåº¦: %s/s\n", formatFileSize(int64(avgSpeed)))
	}
	
	if failed > 0 {
		return fmt.Errorf("æœ‰ %d ä¸ªæ–‡ä»¶ä¸Šä¼ å¤±è´¥", failed)
	}
	
	return nil
}